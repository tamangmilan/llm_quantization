{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# !pip install torch\n",
        "import torch"
      ],
      "metadata": {
        "id": "y_B_RGNsj764"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def asymmetric_quantization(original_weight):\n",
        "  # define the data type that you want to quantized to. In our example, it's INT8\n",
        "  quantized_data_type = torch.int8\n",
        "\n",
        "  # Get the Wmax and Wmin value from the orginal weight which is in FP32\n",
        "  Wmax = original_weight.max().item()\n",
        "  Wmin = original_weight.min().item()\n",
        "\n",
        "  # Get the Qmax and Qmin value from the quantized data type.\n",
        "  Qmax = torch.iinfo(quantized_data_type).max\n",
        "  Qmin = torch.iinfo(quantized_data_type).min\n",
        "\n",
        "  # Calculate the scale value using the scale formula. Datatype - FP32\n",
        "  # Please refer to math section of this post if you want to find out how the formula has been derived.\n",
        "  S = (Wmax - Wmin)/(Qmax - Qmin)\n",
        "\n",
        "  # Calculate the zero point value using the zero point formula. Datatype - INT8\n",
        "  # Please refer to math section of this post if you want to find out how the formula has been derived.\n",
        "  Z = Qmin - (Wmin/S)\n",
        "  # Check if the Z value is out of range\n",
        "  if Z < Qmin:\n",
        "    Z = Qmin\n",
        "  elif Z > Qmax:\n",
        "    Z = Qmax\n",
        "  else:\n",
        "    # Zero point datatype should be INT8 same as the Quantized value.\n",
        "    Z = int(round(Z))\n",
        "\n",
        "  # We have original_weight, scale and zero_point, now we can calculate the quantized weight using the formula we've derived in math section.\n",
        "  quantized_weight = (original_weight/S) + Z\n",
        "\n",
        "  # We'll also round it and also use the torch clamp function to ensure the quantized weight doesn't goes out of range and should remain within Qmin and Qmax.\n",
        "  quantized_weight = torch.clamp(torch.round(quantized_weight), Qmin, Qmax)\n",
        "\n",
        "  # finally cast the datatype to INT8\n",
        "  quantized_weight = quantized_weight.to(quantized_data_type)\n",
        "\n",
        "  # return the final quantized weight.\n",
        "  return quantized_weight, S, Z\n",
        "\n",
        "def asymmetric_dequantization(quantized_weight, scale, zero_point):\n",
        "  # Use the dequantization calculation formula derived in the math section of this post.\n",
        "  # Also make sure to convert quantized_weight to float as substraction between two INT8 values (quantized_weight and zero_point) will give unwanted result.\n",
        "  dequantized_weight = scale * (quantized_weight.to(torch.float32) - zero_point)\n",
        "\n",
        "  return dequantized_weight\n",
        "\n"
      ],
      "metadata": {
        "id": "6UwjwSnKGtOf"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assign random value to the original weight matrix(4,4) parameters (DataType: FP32)\n",
        "# The value of the weight matrix below is same as the one in the diagram above.\n",
        "original_weight = torch.randn((4,4))\n",
        "print(original_weight)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IChyx90ITH7j",
        "outputId": "aeb11004-3a2e-4c53-c8cf-b37f1801251b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.9125, -1.9589, -0.2497, -0.6999],\n",
            "        [ 1.5274, -1.3953,  0.1922,  0.0445],\n",
            "        [ 1.4998,  1.3379,  0.2339,  0.8801],\n",
            "        [-1.6090,  2.3914, -0.1345, -0.9948]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "quantized_weight, scale, zero_point = asymmetric_quantization(original_weight)\n",
        "print(f\"quantized weight: {quantized_weight}\")\n",
        "print(\"\\n\")\n",
        "print(f\"scale: {scale}\")\n",
        "print(\"\\n\")\n",
        "print(f\"zero point: {zero_point}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXYnTURhTXIF",
        "outputId": "f5b24738-f686-4602-c54c-66e2c0c206df"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "quantized weight: tensor([[  40, -128,  -28,  -54],\n",
            "        [  77,  -95,   -2,  -10],\n",
            "        [  75,   65,    1,   39],\n",
            "        [-107,  127,  -21,  -71]], dtype=torch.int8)\n",
            "\n",
            "\n",
            "scale: 0.017060000288720224\n",
            "\n",
            "\n",
            "zero point: -13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "quantized_weight"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCe88JFpTdz2",
        "outputId": "8745a7c3-f515-488e-f8b4-23d4e66ceefe"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  40, -128,  -28,  -54],\n",
              "        [  77,  -95,   -2,  -10],\n",
              "        [  75,   65,    1,   39],\n",
              "        [-107,  127,  -21,  -71]], dtype=torch.int8)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dequantized_weight = asymmetric_dequantization(quantized_weight, scale, zero_point)\n",
        "print(dequantized_weight)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-UhS6ATTg3W",
        "outputId": "34d3e3cd-d21f-47a8-ac7a-f11cae3fe635"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.9042, -1.9619, -0.2559, -0.6995],\n",
            "        [ 1.5354, -1.3989,  0.1877,  0.0512],\n",
            "        [ 1.5013,  1.3307,  0.2388,  0.8871],\n",
            "        [-1.6036,  2.3884, -0.1365, -0.9895]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dequantized_weight"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGwm0f3OUbao",
        "outputId": "3a52a934-4c69-49e9-efe7-9ab8a04c0b93"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.9042, -1.9619, -0.2559, -0.6995],\n",
              "        [ 1.5354, -1.3989,  0.1877,  0.0512],\n",
              "        [ 1.5013,  1.3307,  0.2388,  0.8871],\n",
              "        [-1.6037,  2.3884, -0.1365, -0.9895]])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "quantization_error = (dequantized_weight - original_weight).square().mean()\n",
        "print(quantization_error)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tnljj6hzUeqd",
        "outputId": "60e4991b-f36b-40b9-d94e-d0a363061b2f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.8572e-05)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IE5IR2HAj2hq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}